{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a Car Profitably [Car Price prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work has made in cooperation with Vetak8:\n",
    "#### [GitHub](https://github.com/vetak8)\n",
    "#### [Kaggle](https://www.kaggle.com/vitaliyburlakov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://i.ytimg.com/vi/Qr9S2zYfAfs/maxresdefault.jpg' width= '800px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Target of this project is to:\n",
    "- Collect a dataset from outside sources for training a model. \n",
    "- To make a exploratory data analysis \n",
    "- Try to predict the price of a car with given technical and commercial car's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "The training data already collected from auto.ru  by using dedicated notebook. You may find it in GitHUB in the link below:\n",
    "\n",
    "#### [GitHub_Data_Collector](https://github.com/Paull-dark/Skill_Factory/tree/master/module_6_Cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1.1\"></a>\n",
    "## [Features Defination](sec1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BodyType** -  The type of the Body of car .\n",
    "\n",
    "**Brand** - Name of brand.\n",
    "\n",
    "**color** - Color of the car (hex).\n",
    "\n",
    "**complectation_dict** - specified complecttion of the car.\n",
    "\n",
    "**description** - human's description of the car (given by seller).\n",
    "\n",
    "**engineDisplacement** - Working volume of the engine (in $mm^3$).\n",
    "\n",
    "**enginePower** - Power in Horses.\n",
    "\n",
    "**equipment** - set of auxilliary equipment.\n",
    "\n",
    "**fuelType - Diesel, gasoline electric etc.\n",
    "\n",
    "**image** - url of the image of car.\n",
    "\n",
    "**mileage** - How many kilometers car passed up to the date.\n",
    "\n",
    "**modelDate** - When particular model has been designed.\n",
    "\n",
    "**name** - shows bolume of engine and horse power.\n",
    "\n",
    "**numberOfDoors** - The number of doors in a single car.\n",
    "\n",
    "**parsing_unixtime** - time of parsing the data.\n",
    "\n",
    "**PriceCurrency** - The currency of the car's price.\n",
    "\n",
    "**productionDate** - The date when the car has been released from factory.\n",
    "\n",
    "**sell_id** - id number of the seller.\n",
    "\n",
    "**super_gen** - dictionary with data like: model, price_segment.\n",
    "\n",
    "**vehicleConfiguration** - shows body type, type of gear, volume of engine.\n",
    "\n",
    "**vehicleTransmission** - Gear type.\n",
    "\n",
    "**vendor** - Contry of model's origin.\n",
    "\n",
    "**Владельцы** - How many owners had particular car before.\n",
    "\n",
    "**Владение** - How long the seller own a particular car.\n",
    "\n",
    "**ПТС** - Shows whether the car's documents in original state.\n",
    "\n",
    "**Привод** - Wheel drive (2WF,4WD etc).\n",
    "\n",
    "**Руль** - Left or right Wheel.\n",
    "\n",
    "**Состояние** - condition of a car (good or not).\n",
    "\n",
    "**Таможня** - whether Custom clearance performed.\n",
    "\n",
    "**price** - price in RUB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "# [INDEX](#sec2)\n",
    "\n",
    "<a id=\"sec1\"></a>\n",
    "1. [Description](#sec1)\n",
    "   * [1.1 Features Defination](#sec1.1)\n",
    "2. [INDEX](#sec2)\n",
    "3. [IMPORT LIBRARRIES](#sec3)\n",
    "4. [Functions and Classes](#sec4)\n",
    "5. [Load and Chek the Dataset](#sec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 50)  # Show more rows\n",
    "pd.set_option('display.max_columns', 50)  # Show more columns\n",
    "plt.style.use('ggplot')  # Nice plotting\n",
    "\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lock a RANDOM SEED to keep experiments reproducible.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAABKCAYAAADje3L/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAClklEQVR4nO3aMWsTcRzH4V+8GgMhlrYIDhmK6eoLcDOD+Fp8BdKtW/euvgB9DS55FS4l4HKCpYVSQzEtxDpIHdpaPJPj8ovPM1648P0P+ZAcaQ0Gg6sAWHIPmh4A8DfECkhBrIAUxApIYa3qDZ1OJ/r9fkwmk5jNZnVsAv5DRVFEr9eLsixjOp3eer1yrPr9fgyHw4WMA7hpNBrFeDy+db1yrCaTSUREfPj4OY5PL+ZftoRetp83PaFWr95sNT2hNu+fvW56Qq3e7r1rekJtznut+PTi4e/G3FQ5Vtc//Y5PL+LL8ff51i2p885qP8prt9tNT6jN2frTpifU6vHp6v8t8k+Pl1b7UwmsDLECUhArIAWxAlIQKyAFsQJSECsgBbECUhArIAWxAlIQKyAFsQJSECsgBbECUhArIAWxAlIQKyAFsQJSECsgBbECUhArIAWxAlIQKyAFsQJSECsgBbECUhArIAWxAlIQKyAFsQJSECsgBbECUhArIAWxAlIQKyAFsQJSECsgBbECUhArIAWxAlIQKyAFsQJSECsgBbECUhArIAWxAlIQKyAFsQJSECsgBbECUhArIIW1qjcURREREU82Hi18zLLotn80PaFWl5eXTU+ozfrZ16Yn1OrbRqvpCbU57/0623VjbmoNBoOrKm+4s7MTw+Fw/mUAdxiNRjEej29dr/zNqizL2N7ejoODg5jNZgsZt2x2d3djf3+/6Rm1cb68VvlsRVFEr9eLsizvfL1yrKbTaWxtbcXR0dHc45ZVt9uNk5OTpmfUxvnyWuWzRcS9XfGAHUhBrIAUxApIodjc3Nz7lxsPDw8XPGW5OF9uq3y+VT7bfSr/dQGgCX4GAimIFZCCWAEpiBWQglgBKfwEmmN9h+vL3M8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set project colors\n",
    "colors = ['#001c57', '#50248f', '#a6a6a6', '#38d1ff','#cc3181']\n",
    "sns.palplot(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec4\"></a>\n",
    "# [Functions and Classes](#sec4)\n",
    "[(INDEX)](#sec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  у участников найдена функция по сравнению дата-сетов. Немного преобразовал для удобства восприятия\n",
    "def compare_data_sets(train_df,test_df):\n",
    "    \n",
    "    list_of_names1 = list(train_df.columns)\n",
    "    temp_dict = {}\n",
    "    temp_dict['feature_train'] = list_of_names1\n",
    "    temp_dict['type_train'] = train_df.dtypes\n",
    "    temp_dict['sample_train'] = train_df.loc[1].values\n",
    "    temp_dict['# unique_train'] = train_df.nunique().values\n",
    "    temp_df1 = pd.DataFrame.from_dict(temp_dict)\n",
    "    \n",
    "    \n",
    "    list_of_names2 = list(test_df.columns)\n",
    "    temp_dict2 = {}\n",
    "    temp_dict2['feature_test'] = list_of_names2\n",
    "    temp_dict2['type_test'] = test_df.dtypes\n",
    "    temp_dict2['sample_test'] = test_df.loc[1].values\n",
    "    temp_dict2['# unique_test'] = test_df.nunique().values\n",
    "    temp_df2 = pd.DataFrame.from_dict(temp_dict2)\n",
    "    \n",
    "    temp_insert = pd.DataFrame(columns=['< - >'])\n",
    "    \n",
    "    temp_df = pd.concat([temp_df1,temp_insert, temp_df2], axis=1, sort=False)\n",
    "    temp_df.reset_index(inplace = True)\n",
    "    del temp_df['index']\n",
    "    temp_df['< - >'] = '| - |'\n",
    "    display(temp_df)\n",
    "\n",
    "    temp_dict3 = {}\n",
    "    temp_df3= pd.DataFrame(temp_df)\n",
    "    temp_list  = []\n",
    "    temp_list2  = []\n",
    "    temp_list3  = []\n",
    "    temp_list4  = []\n",
    "    temp_list5  = []\n",
    "\n",
    "    for i in range(len(temp_df)):\n",
    "        if str(temp_df3['type_train'][i]) != str(temp_df3['type_test'][i]):\n",
    "            temp_list.append(temp_df3['feature_train'][i])\n",
    "            temp_list2.append(temp_df3['feature_test'][i])\n",
    "            temp_list3.append(str(temp_df3['type_train'][i]) + ' != ' + str(temp_df3['type_test'][i]))\n",
    "            temp_list4.append(i)\n",
    "        if temp_df3['# unique_test'][i]>0 and temp_df3['# unique_train'][i]/temp_df3['# unique_test'][i] > 2:\n",
    "            temp_list5.append(i)\n",
    "            \n",
    "    temp_dict3['index']= temp_list4\n",
    "    temp_dict3['feature_train']= temp_list\n",
    "    temp_dict3['не совпадают типы'] = temp_list3\n",
    "    temp_dict3['feature_test']= temp_list2\n",
    "\n",
    "    temp_df4 = pd.DataFrame.from_dict(temp_dict3)\n",
    "    temp_df4.set_index('index',inplace=True)\n",
    "\n",
    "    print(f'Резюме:\\n 1. Не совпали типы в:= {len(temp_df4)} столбцах\\n')\n",
    "    print(f'2. Уникальные значения различаются в:= {len(temp_list5)} столбцах {temp_list5}')\n",
    "    display(temp_df4)\n",
    "\n",
    "# # После нескольких запусков выявили список столбцов, не полезных в дальнейшей работе\n",
    "# # Это признаки, имеющие единственное значение, признаки не имеющие пары в обучающем и тестовом датасетах, признаки, \n",
    "# # содержащие консолидированную информацию, уже сохраненную в других признаках\n",
    "\n",
    "# drop_cols = ['car_url', 'sell_id', 'image', 'hidden', 'parsing_unixtime', 'Состояние']\n",
    "\n",
    "# for col in drop_cols:\n",
    "#     if col in list(df_train.columns):\n",
    "#         df_train.drop(columns=[col], inplace=True)\n",
    "#     if col in list(df_test.columns):\n",
    "#         df_test.drop(columns=[col], inplace=True)\n",
    "    \n",
    "# check_df_before_merg(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_report(data):\n",
    "    ''' Function is called for generating of dataset profile-report'''\n",
    "\n",
    "    profile = data.profile_report(\n",
    "        title='Credit Scoring',\n",
    "        progress_bar=False,\n",
    "        correlations={\n",
    "            'pearson': {'calculate': True},\n",
    "            'spearman': {'calculate': True},\n",
    "            'kendall': {'calculate': True},\n",
    "            'phi_k': {'calculate': True},\n",
    "            'cramers': {'calculate': True}        \n",
    "        },\n",
    "        \n",
    "        interactions={\n",
    "            'continuous': True,\n",
    "            'targets': []\n",
    "        },\n",
    "        missing_diagrams={\n",
    "            'heatmap': True,\n",
    "            'dendrogram': True,\n",
    "            'matrix': True\n",
    "        },\n",
    "        vars={\n",
    "            'cat' : {'n_obs':10}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxplot(data, X_axis, Y_axis, hue=None):\n",
    "    '''Function is called to plot boxplots'''\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    sns.boxplot(x=X_axis, y=Y_axis, hue=hue, data=data, palette=colors)\n",
    "    plt.xticks(rotation=45)\n",
    "    ax.set_title(f'Boxplot for {X_axis} and {Y_axis}', fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def label_encoder(self, column):\n",
    "        le = LabelEncoder()\n",
    "        self.data[column] = le.fit_transform(self.data[column])\n",
    "\n",
    "    def hot_enc(self, column):\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        aux_df = pd.DataFrame(ohe.fit_transform(self.data[[column]]))\n",
    "        aux_df.columns = ohe.get_feature_names([f'hot_{column}'])\n",
    "        self.data = self.data.drop(col, axis=1)\n",
    "        self.data = pd.concat([self.data, aux_df], axis=1)\n",
    "        return self.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_vars(data, col='education', random_proba=True):\n",
    "    '''Function is called for filling of missing data'''\n",
    "    # With using probability and random choise\n",
    "\n",
    "    if random_proba:\n",
    "        col_name = data[col].value_counts().index.to_list(\n",
    "        )  # get list of values\n",
    "        col_distr = data[col].value_counts(\n",
    "            normalize=True).values  # get l;ist of probs\n",
    "        missing = data[col].isnull()  # flag of missing val\n",
    "        # substitute values from the list of names in accordance with the probability of meeting the name\n",
    "        data.loc[missing, [col]] = np.random.choice(col_name,\n",
    "                                                    size=len(data[missing]),\n",
    "                                                    p=col_distr)\n",
    "\n",
    "    # Using  most common in  column\n",
    "    data[col] = data[col].fillna(data[col].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix(data, det=True, pltx=10, plty=10):\n",
    "    '''Funcion is called for making correlation matrix'''\n",
    "    \n",
    "    X = data.corr()\n",
    "    if det:\n",
    "        \n",
    "        evals,evec = np.linalg.eig(X)\n",
    "        ev_product = np.prod(evals)\n",
    "    \n",
    "        print(f'Rank of Matrix: {np.linalg.matrix_rank(X)}')\n",
    "        print(f'Determinant of matrix: {np.round(ev_product,4)}')\n",
    "        print(f'Shape of matrix: {np.shape(X)}')\n",
    "    \n",
    "    plt.figure(figsize=(pltx,plty))\n",
    "    sns.heatmap(X,vmin=0,vmax=.9,annot=True,square=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec5\"></a>\n",
    "# [5.Load and Chek the Dataset](#sec5)\n",
    "[(INDEX)](#sec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_parsed_18_05_21.csv',low_memory=False)\n",
    "df_test = pd.read_csv(r'C:\\Users\\wangshu202040\\projects_SF\\module_6_Cars\\test.csv\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['price'] = np.nan\n",
    "\n",
    "# let's mark where is train where is test set.\n",
    "df_train['sample'] = 'train'  # train\n",
    "df_test['sample'] = 'test'  # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train Dataset:(103263, 35) \n",
      "Shape of Test Dataset:(34686, 34) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'Shape of Train Dataset:{df_train.shape}\\nShape of Test Dataset:{df_test.shape} \\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the proper processing of features, we need to combine train and test sets into a one dataset.\n",
    "\n",
    "However, as we scrapped data from web, we have to compare whar we scrapped with test set and then fix it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_data_sets(df_train,df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
