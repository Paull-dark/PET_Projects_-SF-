{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lZjmJDLgPfw"
   },
   "source": [
    "# Find Dishonest Restaurant\n",
    "<img src=\"https://www.netclipart.com/pp/m/349-3494556_forex-scams-by-dishonest-person-lying-cartoon.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7w1uEcTgPf6"
   },
   "source": [
    "## Description\n",
    "\n",
    "Sometimes, some dishonest restaurants cheating TripAdvisor and their guests by winding up the rating higher than it should be.\n",
    "\n",
    "The main aim of the project is to try to predict the rating of the restaurant with given data.\n",
    "\n",
    "In case if the predictions of our model have significant differences from the actual result, then, most likely we found a dishonest restaurant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hKo_pDegPf6"
   },
   "source": [
    "### Column Defination\n",
    "\n",
    "Restaurant_id — restaurant / restaurant chain identification number;\n",
    "\n",
    "City — In what city it is located;\n",
    "\n",
    "Cuisine Style — related to a restaurant cuisine;\n",
    "\n",
    "Ranking — the place that this restaurant occupies among all restaurants in its city;\n",
    "\n",
    "Rating — restaurant rating according to TripAdvisor (Target Variable);\n",
    "\n",
    "Price Range — restaurant price range;\n",
    "\n",
    "Number of Reviews — Number of Reviews ;\n",
    "\n",
    "Reviews — data about two reviews that are displayed on the restaurant's website;\n",
    "\n",
    "URL_TA — URL on TripAdvisor;\n",
    "\n",
    "ID_TA — Identificator of restaurant in TripAdvisor's DataBase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOeC7IIagPf7"
   },
   "source": [
    "---\n",
    "### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w64WuxVRgPf7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-495da8d45f24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m  \u001b[1;31m# for sentiment analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m  \u001b[1;31m# for creating cloud of words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from jupyterthemes import jtplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from textblob import TextBlob  # for sentiment analysis\n",
    "from wordcloud import WordCloud  # for creating cloud of words\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 50)  # Show more rows\n",
    "pd.set_option('display.max_columns', 50)  # Show more columns\n",
    "plt.style.use('ggplot')  # Nice plotting\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "C1L6-RcygPf9",
    "outputId": "0e77a01b-716b-4e23-ea2d-b4ab683708cf"
   },
   "outputs": [],
   "source": [
    "# colors = ['#001c57', '#50248f', '#a6a6a6', '#38d1ff']\n",
    "colors = ['#50248f', '#38d1ff']\n",
    "sns.palplot(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0llH3NBgPf-"
   },
   "source": [
    "### 1.  Read and Chek the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTSEgJp7gPf_",
    "outputId": "6c0a8770-a1f9-4a8a-ef80-7128336de054",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_task.csv')\n",
    "print(f'Dataset shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2aRTDR9gPf_"
   },
   "source": [
    "### 1.1 Show basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "4KAklvTAgPf_",
    "outputId": "a8577476-4ff6-4774-e495-7f6a3a6ca3ba",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vE_Hr9ngPgA"
   },
   "source": [
    "### 1.2 Show the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "wLhLhPXHgPgA",
    "outputId": "59b8a637-dbc5-4e23-8007-59999ecfe316"
   },
   "outputs": [],
   "source": [
    "dtype_df = df.dtypes.reset_index()\n",
    "dtype_df.columns = ['Count', 'Column Type']\n",
    "dtype_df.groupby('Column Type').agg('count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B37DPQsEgPgA"
   },
   "source": [
    "Let's see what type of data in each column-cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiUZ8pBBgPgA",
    "outputId": "d82a9866-9f48-4c2c-d65e-e6da0d4761ed"
   },
   "outputs": [],
   "source": [
    "for i, j in enumerate(df.columns):\n",
    "    print(j, type(df.loc[1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-lj-48BgPgB"
   },
   "source": [
    "Well, it is more interesting. Let's briefly see at the content of object data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hW_qI4l9gPgB",
    "outputId": "4547aca3-9229-46dc-b4a6-6d4477592dab"
   },
   "outputs": [],
   "source": [
    "obj = df.dtypes[df.dtypes == 'object'].index\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Szp3C1ajgPgB",
    "outputId": "62095637-da1b-4156-aca8-d51d7f796143"
   },
   "outputs": [],
   "source": [
    "for i in obj:\n",
    "    print(f'Col Name: {i}, Content: {df[i].unique()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raMEideGgPgC"
   },
   "source": [
    "Well, that is clearly obvious,that some data in columns pretend to be as a list, however it is string or float type.\n",
    "\n",
    "Such as:\n",
    " - column Cuisine Style is looks like a list, but has float64 type;\n",
    " - column Reviews looks like nested list with following template [[ comment_1 , comment_2 ], [date1 , date2]], but in fact it has str type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V4nw58ogPgC"
   },
   "source": [
    "Rename columns removing spaces and substituting capital letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "id": "lCMKwu-zgPgC",
    "outputId": "66085232-5373-459b-ff8c-726528f01c8f"
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Restaurant_id': 'restaurant_id',\n",
    "                   'City': 'city',\n",
    "                   'Cuisine Style': 'cuisine_style',\n",
    "                   'Ranking': 'ranking',\n",
    "                   'Rating': 'rating',\n",
    "                   'Price Range': 'price_range',\n",
    "                   'Number of Reviews': 'reviews_number',\n",
    "                   'Reviews': 'reviews',\n",
    "                   'URL_TA': 'url_ta',\n",
    "                   'ID_TA': 'id_ta'}, inplace=True)\n",
    "# show the data\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOWS7OTegPgC"
   },
   "source": [
    "### 1.3 Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe an empty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "id": "TB0vtl07gPgD",
    "outputId": "5b333bc3-bfc0-4811-da58-340ba6e0ec4f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot missing values\n",
    "cols = df.columns\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "sns.heatmap(df[cols].isnull(), cmap=sns.color_palette(colors))\n",
    "\n",
    "# Show in percents\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print(f'{col} - {round(pct_missing*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vs619a5gPgD"
   },
   "source": [
    "---\n",
    "## Resume\n",
    "---\n",
    "\n",
    " - DataSet has 40k rows and 10 columns.\n",
    " - Column 'cuisine_style' has 23% of missing values\n",
    " - Column 'price_range' has 35% of missing values\n",
    " - Column 'reviews_number' has 6% of missing values while column 'reviews' has no any single missing value. Here is a discrepancy. If we visually check the content of the column 'reviews', we find the following value :'[[],[]]'. Definatelly it is a missing value which need to be treated in further data-processing.\n",
    " - Type in particular cell sometimes differ with pd.dtypes. Need to take care about that in further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAktq2EygPgD"
   },
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxf9-HJWgPgD"
   },
   "source": [
    "### 2.1 Target Variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "TrHLnTRhgPgE",
    "outputId": "69bce60f-cf38-47ca-b5b7-6a33cfefdc63"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "sns.distplot(df.rating.values, bins=10, color=colors[0])\n",
    "plt.title('Rating Distribution\\n', fontsize=15)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Quantity (frequency)')\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.boxplot(df.rating.values, color=colors[1])\n",
    "plt.title('Rating Distribution\\n', fontsize=15)\n",
    "plt.xlabel('Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjhAGLzpgPgE",
    "outputId": "23f032c8-4158-45f9-db7a-fc5162c5193b"
   },
   "outputs": [],
   "source": [
    "df['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFhG_djvgPgE"
   },
   "source": [
    "The Target variable has a normal distribution shifted to the right side of 1 to 5. The first and third quartiles are in the range from  3.5 to 4.5, the median is 4. Also outliers has been observed for target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVeCm-5JgPgE"
   },
   "source": [
    "### 2.2 Restaurant_Id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdLlm2epgPgF",
    "outputId": "8bf20546-471a-4f85-b230-298b3646faa1"
   },
   "outputs": [],
   "source": [
    "print(f'Unique Id quantity: {df.restaurant_id.nunique()}')\n",
    "df['restaurant_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ghaCEM-gPgF"
   },
   "source": [
    "---\n",
    "\n",
    "Well, the total quantity of rows is 40k while number of unique id is 11k.\n",
    "\n",
    "We may see some dublicates here. But:\n",
    "\n",
    "With a reference to a column description it may says us that we have some chain restaurants in dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdMmXH_pgPgF"
   },
   "source": [
    "### 2.3 City column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7TG5xGBgPgF"
   },
   "source": [
    "How are cities distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "tBbYCjS9gPgF",
    "outputId": "afe9c83c-840a-4a0a-de07-c06ddf59ab6d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5), dpi=100)\n",
    "sns.countplot(df['city'], order=df['city'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Cities Distribution\\n', fontsize=15)\n",
    "plt.xlabel('City Name')\n",
    "plt.ylabel('Quantity (frequency)')\n",
    "\n",
    "print(f'Total Number of Cities in DataSet: {df.city.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rprEXiv-gPgG"
   },
   "source": [
    "---\n",
    "\n",
    "The overwhelming majority of restaurants presented in the dataset located in London, Paris, Madrid. \n",
    "\n",
    "All cities are European.\n",
    "\n",
    "The city of Oporto is not identified. It is actually the name of the restaurant in Porto(Portugal)\n",
    "\n",
    "Most likely the city shall have a name as Porto instead of Oporto.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PObNaFkbgPgG"
   },
   "source": [
    "### 2.4 Cuisine_style column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFyjkAGWgPgH"
   },
   "source": [
    "First of all, we have to manage the list of cuisines in a way that we can use the data and produce some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hN2ull82gPgH",
    "outputId": "83a56de8-a169-4259-dd8e-cb5e799c7ba2"
   },
   "outputs": [],
   "source": [
    "# Before we start, we need to save an information in the dataset, where there were a missing values\n",
    "\n",
    "# Create a column where indicate that Cuisine is not presented for this restaurant\n",
    "df['cuisine_style_empty'] = df['cuisine_style'].isnull().astype('uint8')\n",
    "\n",
    "# Fill missing values in column with 'unknown'\n",
    "df['cuisine_style'] = df['cuisine_style'].fillna(\"['unknown']\")\n",
    "\n",
    "# convert string in the column into a list\n",
    "df['cuisine_style'] = df['cuisine_style'].apply(lambda x: eval(x))\n",
    "\n",
    "# Create separate dataframe for the analysis\n",
    "\n",
    "df1 = df[['city', 'cuisine_style', 'ranking', 'rating',\n",
    "          'reviews_number']].explode('cuisine_style')\n",
    "\n",
    "# -1 cos we already filled missed value. Dont count it\n",
    "print(df1['cuisine_style'].nunique()-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NH5P7DhgPgI"
   },
   "source": [
    "Check  a top 10 of the most common cuisine styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "-Nur_JO6gPgI",
    "outputId": "c67ef566-0df9-4822-fef9-cb8a008714d3"
   },
   "outputs": [],
   "source": [
    "df_cuisine_style = df1['cuisine_style'].value_counts(\n",
    ").sort_values(ascending=False)[:10]\n",
    "\n",
    "count_ths = np.arange(0, 1.3e4, 5e3)\n",
    "count = np.arange(0, 20, 5)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot()\n",
    "\n",
    "\n",
    "plt.bar(x=df_cuisine_style.index, height=df_cuisine_style, color=colors[0])\n",
    "\n",
    "plt.yticks(count_ths, count)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Total Places (Thousands)')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.title('Top 10 most common cuisines')\n",
    "ax.tick_params(direction='out', length=0, width=0, colors='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTrCem1mgPgI"
   },
   "source": [
    "--- \n",
    "The dataset has 125 unique cuisines.\n",
    "\n",
    "Vegetarian Friendly places are clearly the most common ones around Europe, followed by mostly European-style cuisine.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAu0hNkLgPgI"
   },
   "source": [
    "Which are the cuisines that people tend to review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FlmIT_GgPgI"
   },
   "outputs": [],
   "source": [
    "df_cuisine_style = df1.groupby(\n",
    "    'cuisine_style').reviews_number.sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "Oem4Ka6tgPgJ",
    "outputId": "5873ce04-b8e6-400d-f9c1-52c21976648c"
   },
   "outputs": [],
   "source": [
    "count_ths = np.arange(0, 3.3e6, 5e5)\n",
    "count = np.arange(0, 9.3, 0.5)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot()\n",
    "\n",
    "plt.bar(x=df_cuisine_style.index, height=df_cuisine_style, color=colors[1])\n",
    "\n",
    "plt.yticks(count_ths, count)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Total Reviews (Million)')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.title('Top 10 most reviewed cuisines')\n",
    "ax.tick_params(direction='out', length=0, width=0, colors='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubeIx9XZgPgJ"
   },
   "source": [
    "---\n",
    "\n",
    "The chart is more or less simillar with above one.But it's notable that the Vegan and Gluten Free Options are very likely to be reviewed by the customers.\n",
    "\n",
    "People are not tend to review restaurants where cuisins are not shown. So we made a right desicion to keep (but not delete) rows with missing cuisins by replacing nan value to 'unknown'. Perhaps this info may help us in further modeling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58o-xckCgPgJ"
   },
   "source": [
    "### 2.5 Ranking column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39kD3s3agPgK"
   },
   "source": [
    "How is it distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "cmaMMJklgPgK",
    "outputId": "6f06e8fa-c9e6-4872-9acf-2f2dd7da34a7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "sns.distplot(df.ranking.values, bins=25, color=colors[0])\n",
    "plt.title('Ranking Distribution\\n', fontsize=15)\n",
    "plt.xlabel('Ranking')\n",
    "plt.ylabel('Quantity (frequency)')\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.boxplot(df.ranking.values, color=colors[1])\n",
    "plt.title('Ranking Distribution\\n', fontsize=15)\n",
    "plt.xlabel('Ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWdVCdYtgPgK",
    "outputId": "2f160d4a-9db4-45a1-f761-d9484aade671",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['ranking'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk5YXuyQgPgK"
   },
   "source": [
    "---\n",
    "\n",
    "The Ranking distribution shifted to the left side and scattered from 1 to 16444. The first and third quartiles are in the range from 973 to 5260, the median is 2285.\n",
    "\n",
    "However, with a reference to the data description, the Ranking is the place that this restaurant occupies among all restaurants in its city. So we cannot observe it separately from cities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p35OUCbSgPgL"
   },
   "source": [
    "So, let's plot a distribution of a ranking depend on city (take 10-top cities in dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "YlKyhDG7gPgL",
    "outputId": "5ad005f0-6ac6-439d-8925-ea13057ed2a2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for city in (df['city'].value_counts())[0:10].index:\n",
    "    sns.distplot(df['ranking'][df['city'] == city], kde=False, label=city)\n",
    "\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.title('Ranking Distribution among cities\\n', fontsize=15)\n",
    "plt.xlabel('Ranking')\n",
    "plt.ylabel('Quantity (frequency)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfGrw4brgPgL"
   },
   "source": [
    "---\n",
    "\n",
    "Well, as we see the ranking has normal distribution in each separate city. And as we already know , London is taking a top place by presented restaurants. So it in not surprised, that why do we have a shifting of distribution in a left side. Big cities has lots of restaurants.\n",
    "\n",
    "Then in a further feature engeniring section (below) we need to consider this by creating equivalent ranking.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct1SMYqvgPgL"
   },
   "source": [
    "Chek the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "zFPOqb1FgPgL",
    "outputId": "7d44c5b2-9476-4901-934f-ce8d6c6cc0e7"
   },
   "outputs": [],
   "source": [
    "X = df.corr()\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "sns.heatmap(X, vmax=.7, square=True, annot=True)\n",
    "\n",
    "print(f'Rank of Matrix: {np.linalg.matrix_rank(X)}')\n",
    "print(f'Determinat of matrix :{np.round(np.linalg.det(X),3)}')\n",
    "print(f'Shape of matrix :{np.shape(X)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oevBTnNfgPgM"
   },
   "source": [
    "---\n",
    "\n",
    "Here we can see some correlations with target variable.\n",
    "\n",
    "There is no correlations between features. It is also confirmed by rank of correlation matrix. It is a full rank matrix.\n",
    "\n",
    "Most likely, we won't have a problems in a modeling\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbFKr1H0gPgM"
   },
   "source": [
    "### 2.6 Price range column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tU5g3Hl6gPgM"
   },
   "source": [
    "First of all, with a reference to a section 1, we know that this column has 35% of nan values and presented as dollar symbol\n",
    "\n",
    "Let's replace these symbols in the dataset for the three price ranges with  more intuitive (cheap - medium - high ranges) and replace the NaN ones (set as not available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opvZNlbbgPgM"
   },
   "outputs": [],
   "source": [
    "df['price_range'] = df['price_range'].fillna('NA')\n",
    "price_ranges = {'$': 'Cheap', '$$ - $$$': 'Medium',\n",
    "                '$$$$': 'High', 'NA': 'NotAvailable'}\n",
    "df['price_range'] = df['price_range'].map(price_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "LNgqpqObgPgM",
    "outputId": "ebfe8b0b-2d29-4959-ab36-01ad7cd89838"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(x='price_range', y='rating', data=df)\n",
    "\n",
    "plt.title('Price Range to Rating\\n', fontsize=15)\n",
    "plt.xlabel('Price range')\n",
    "plt.ylabel('Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vF6etQKvgPgN"
   },
   "source": [
    "---\n",
    "\n",
    "Well, restaurants with high prices and cheap prices getting low ratings less often than restaurants with a medium level\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrRkHaQtgPgN"
   },
   "source": [
    "### 2.7 Reviews number column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bQy0-gmgPgO"
   },
   "source": [
    "---\n",
    "\n",
    "We already know that this column has nan values. Also we know that The most reviewable cuisin is vegan\n",
    "\n",
    "Missing values will be filled in Feature engineering section.\n",
    "\n",
    "Important Note. \n",
    "\n",
    "Filling the missing data must be done in a complex with proceeding the reviews column as we note that there is some descripancy between review numbers and revies itself\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txIErOrTOJgn"
   },
   "source": [
    "### 2.8 Reviews column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G0y6H-ec4ie"
   },
   "source": [
    "#### 2.8.1 Pre-processing and analyse of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgbga4TpOvxm"
   },
   "source": [
    "Let's re-call what have we seen in section 1 of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OQhLsFXgPgP",
    "outputId": "647217fe-3ca3-4166-c886-802be9b72835"
   },
   "outputs": [],
   "source": [
    "print(df['reviews'][0])\n",
    "print(df['reviews'][3])\n",
    "print(f'Govno {type(df.loc[1][\"reviews\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEKP2JL_PCTV"
   },
   "source": [
    "As was mentioned above the content has structural data - [ [ ],[ ] ].\n",
    "\n",
    "**However** it is not a list, but just a string type of variable.\n",
    "\n",
    "Then, we want to extract the data form the colums 'reviews' into a 4 independent colums and remove original one from dataset.\n",
    "\n",
    "In the end we shall get following columns in our dataset:\n",
    "\n",
    "***Review_1*** - we put review No.1 (if any).\n",
    "\n",
    "***Date_1*** - we put the date when the review was added\n",
    "\n",
    "***Review_2*** - we put review No.2 (if any).\n",
    "\n",
    "***Date_2*** - we put the date when the review was added\n",
    "\n",
    "***Diff_rev*** - Time difference in days between first and second review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4ZRu8v-gPgQ"
   },
   "outputs": [],
   "source": [
    "# create a template for search\n",
    "lrx = re.compile('\\[\\[.*\\]\\]')\n",
    "\n",
    "\n",
    "def review_extraction(row):\n",
    "    '''Function is called for extracting data from column \n",
    "    reviews and splitting it out into a separate columns\n",
    "    INPUT: Whole dataset\n",
    "    OUTPUT: Dataset with additional columns'''\n",
    "\n",
    "    cell = row['reviews']\n",
    "    aux_list = [[], []]  # create an auxilliary list for saving temp.data\n",
    "    if type(cell) == str and lrx.fullmatch(cell):  # compare with searech template\n",
    "        nan = None\n",
    "        aux_list = eval(cell)  # transform into a list\n",
    "\n",
    "    row['first_review'] = aux_list[0][1] if len(aux_list[0]) > 1 else nan\n",
    "    row['last_review'] = aux_list[0][0] if len(aux_list[0]) > 0 else nan\n",
    "\n",
    "    row['first_date'] = pd.to_datetime(\n",
    "        aux_list[1][1] if len(aux_list[1]) > 1 else nan)\n",
    "    row['last_date'] = pd.to_datetime(aux_list[1][0] if len(\n",
    "        aux_list[1]) > 0 else nan, format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "    row['first_date'] = pd.to_datetime(row['first_date'])\n",
    "    row['last_date'] = pd.to_datetime(row['last_date'])\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "wDWwJCkugPgQ",
    "outputId": "a4ff13ca-bd2d-48bd-8290-184ba5c347e0"
   },
   "outputs": [],
   "source": [
    "# apply the function to dataset and see the result\n",
    "df = df.apply(review_extraction, axis=1)\n",
    "\n",
    "# show data\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2KAjw9eRkws"
   },
   "source": [
    "Create a column with time difference between first and second reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mu6eRQ6gPgQ"
   },
   "outputs": [],
   "source": [
    "# Create a function to transform date to days\n",
    "\n",
    "def get_days(timedelta):\n",
    "    '''transform date to a day'''\n",
    "    return timedelta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "XoO0FO-cgPgQ",
    "outputId": "3c2f0db1-487f-4775-f1dc-292ca5e245a4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find a diffderence between date of the first review and the last one\n",
    "# add this information into a new column\n",
    "\n",
    "df['diff_rev'] = df['last_date'] - df['first_date']\n",
    "\n",
    "# call the function and get difference in days\n",
    "df['diff_rev'] = df['diff_rev'].apply(get_days)\n",
    "\n",
    "# show data\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df.diff_rev.values, color=colors[0])\n",
    "plt.title('Days betweem comments Distribution\\n', fontsize=15)\n",
    "plt.xlabel('Days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, here are negative values. That might mean that some dates are not refer to a first placed comment. Means it is inverted.\n",
    "\n",
    "Let's fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply revert a sign  to a positive where it is negative\n",
    "df['diff_rev'] = df['diff_rev'].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A restaurant's rating may depend not only on how much time has passed between the last two reviews, but also on how many days have passed since the last review was posted to the current date.\n",
    "\n",
    "Create a relevant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DATE = pd.to_datetime('12/01/2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_from_last_rev'] = df['last_date'].apply(\n",
    "    lambda date: CURRENT_DATE - date)\n",
    "df['days_from_last_rev'] = df['days_from_last_rev'].apply(get_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfYILPLlgPgR",
    "outputId": "53260535-9308-495d-bc6c-7aad9420a30a"
   },
   "outputs": [],
   "source": [
    "# check how many cells with reviews have no revierw\n",
    "df[['first_review', 'last_review']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zd4ZzJZETUXU",
    "outputId": "2924b19b-1e2e-429d-f7e4-389257b1327c"
   },
   "outputs": [],
   "source": [
    "# check how many cells reviews_number have no review\n",
    "df['reviews_number'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf-ype5MZCai"
   },
   "source": [
    "Now, let's sort our dataset and compare mising reviews with missing reviews number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "441CNpfOZRYI",
    "outputId": "11eca37a-3ab5-4478-fcc6-1f289f5484ff"
   },
   "outputs": [],
   "source": [
    "no_rev_num = df[df['reviews_number'].isnull()]\n",
    "no_rev_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGRs2pyZZp7p",
    "outputId": "d1fe74a7-8e22-449d-b22c-b56c151adda6"
   },
   "outputs": [],
   "source": [
    "no_rev_num[['first_review', 'last_review']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1wLnKWpaN5i"
   },
   "source": [
    "That's pretty interesting. The review number actually doesn't show accurate information with a number of reviews. For example, in the feedback columns we have at least one review but it is not depicted in the review's number.\n",
    "\n",
    "Probably we need to drop the columns with the number of reviews or fill somehow the missing data. We will decide it in section 3 'Feature engineering'\n",
    "\n",
    "Let's go ahead with analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vj-7WdNrbJPC"
   },
   "source": [
    "Before we start, let's create two new vectors that indicate to us what 'review' has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeJcOjVWbk5G"
   },
   "outputs": [],
   "source": [
    "# Create a column which indicate that review is not avaliable\n",
    "df['first_review_miss'] = df['first_review'].isnull().astype('uint8')\n",
    "df['last_review_miss'] = df['last_review'].isnull().astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "An8x_bzIb_wN",
    "outputId": "ce70efa8-85dd-43f6-fa37-7f29b4770911",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace Nan values with 'No comment' for further data proceeding\n",
    "df['last_review'] = df['last_review'].fillna('no comment')\n",
    "df['first_review'] = df['first_review'].fillna('no comment')\n",
    "\n",
    "# show data\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNcTbGaedIn-"
   },
   "source": [
    "#### 2.8.2 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSASzJr-dWN4"
   },
   "source": [
    "For a more convenient analyze let's withdraw columns with reviews only and create a new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "sdHUDSLycn3G",
    "outputId": "0fffcb48-9f7c-4ee9-cb64-29f90b155fe1"
   },
   "outputs": [],
   "source": [
    "df_sentiment = df[['first_review', 'last_review']]\n",
    "\n",
    "# show data\n",
    "df_sentiment.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4VTSuVBd7cV"
   },
   "source": [
    "Clean the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-fgegfMcn9C"
   },
   "outputs": [],
   "source": [
    "# Create a function to clean comments\n",
    "\n",
    "def cleanTxt(text):\n",
    "    '''Function is called for cleaning text from trash\n",
    "    INPUT: dirty string\n",
    "    OUTPUT: More or less clean string'''\n",
    "\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Remove @\n",
    "    text = re.sub(r'#', '', text)  # remove #\n",
    "    text = re.sub('^a-zA-Z', ' ', text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)  # remove hyperlink\n",
    "    text = re.sub(r'👍🏻', '', text)\n",
    "    # there are much more emoji. I don't know how to identify them so far\n",
    "    text = re.sub(r'🍕', '', text)\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    #text = text.split()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KQ-uUrjcn_6"
   },
   "outputs": [],
   "source": [
    "# Apply function to clean a text\n",
    "\n",
    "df_sentiment['first_review'] = df_sentiment['first_review'].apply(cleanTxt)\n",
    "df_sentiment['last_review'] = df_sentiment['last_review'].apply(cleanTxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxFCtIsLgOb6"
   },
   "source": [
    "Generate subjectivity and polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kGv_94qcoCZ"
   },
   "outputs": [],
   "source": [
    "# Create a function to get the subjectivity\n",
    "def get_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity\n",
    "\n",
    "\n",
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "mQRAjW4PcoE0",
    "outputId": "d9feb820-188a-4fc5-ee84-ce40817f0de1"
   },
   "outputs": [],
   "source": [
    "# Create new cols and call the func\n",
    "\n",
    "df_sentiment['subjectivity_fst'] = df_sentiment['first_review'].apply(\n",
    "    get_subjectivity)\n",
    "df_sentiment['subjectivity_snd'] = df_sentiment['last_review'].apply(\n",
    "    get_subjectivity)\n",
    "df_sentiment['polarity_fst'] = df_sentiment['first_review'].apply(get_polarity)\n",
    "df_sentiment['polarity_snd'] = df_sentiment['last_review'].apply(get_polarity)\n",
    "# show data\n",
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6fmyfZZgl2c"
   },
   "source": [
    "Let's see to most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "oFUTrS0QcoHu",
    "outputId": "cb55e6ed-c16b-4098-f84b-9ffc47189aab"
   },
   "outputs": [],
   "source": [
    "# Plot Word Cloud\n",
    "all_words_1 = ' '.join(\n",
    "    [reviews for reviews in df_sentiment['first_review'] if reviews != 'no comment'])\n",
    "all_words_2 = ' '.join(\n",
    "    [reviews for reviews in df_sentiment['last_review'] if reviews != 'no comment'])\n",
    "all_words = all_words_1 + all_words_2\n",
    "wordCloud = WordCloud(width=500, height=300, random_state=21,\n",
    "                      max_font_size=119).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3S_YhrQg9If"
   },
   "source": [
    "As we may see, the most frequent words are 'Nice, good', 'food' etc. So people tend to remain more positive reviews and often mention 'food'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVz6r00HkIue"
   },
   "source": [
    "Let's create a new column where we identify the sentiment itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nrCrq9OocoKj"
   },
   "outputs": [],
   "source": [
    "# Create a function to compute the negative, neutral and positive analysis\n",
    "\n",
    "def get_analysis(score):\n",
    "    if score < 0:\n",
    "        return 'negative'\n",
    "    elif score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "qgbfnfp6hmOM",
    "outputId": "c0449e24-9feb-4e8d-92e1-6c164e1900b0"
   },
   "outputs": [],
   "source": [
    "df_sentiment['analysis_fst'] = df_sentiment['polarity_fst'].apply(get_analysis)\n",
    "df_sentiment['analysis_snd'] = df_sentiment['polarity_snd'].apply(get_analysis)\n",
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygTx-ys9hmRP"
   },
   "outputs": [],
   "source": [
    "# # Print all of the positive reviews\n",
    "\n",
    "# j=1\n",
    "# sortedDF_1 = df_sentiment.sort_values(by='polarity_1')\n",
    "# for i in range(0,sortedDF_1.shape[0]):\n",
    "#   if (sortedDF_1['analysis_1'][i] == 'positive'):\n",
    "#     print(str(j)+ ')' +sortedDF_1['review_1'][i])\n",
    "#     print()\n",
    "#     j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rw8krgQMiwQg"
   },
   "source": [
    "Let's check how many positive feedback we have and how they changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EoQmYuj-hmUE",
    "outputId": "bee115a4-df05-41cc-b8a1-05f84c7671e2"
   },
   "outputs": [],
   "source": [
    "# Get the percentage of positive reviews\n",
    "p_rev = df_sentiment[df_sentiment['analysis_fst'] == 'positive']\n",
    "p_rev = p_rev['first_review']\n",
    "round((p_rev.shape[0] / df_sentiment.shape[0])*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-M20Lo-hmW9",
    "outputId": "7c466f55-e771-4e0b-a78c-c9f80fc12548"
   },
   "outputs": [],
   "source": [
    "# Get the percentage of positive reviews\n",
    "p_rev = df_sentiment[df_sentiment['analysis_snd'] == 'positive']\n",
    "p_rev = p_rev['last_review']\n",
    "round((p_rev.shape[0] / df_sentiment.shape[0])*100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1YKCzIei4p_"
   },
   "source": [
    "Well, we have increased positive feedbacks since the first review placed on the website and the last review. Interesting why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFJgcc8JjiFz"
   },
   "source": [
    "Let's check how much negative feedback we have and how they changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZXTCniFhme4",
    "outputId": "241c2764-d76f-48f3-9c59-e6c61e965f56"
   },
   "outputs": [],
   "source": [
    "# Get the percentage of negative reviews\n",
    "n_rev = df_sentiment[df_sentiment['analysis_fst'] == 'negative']\n",
    "n_rev = n_rev['first_review']\n",
    "round((n_rev.shape[0] / df_sentiment.shape[0])*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urSZb4dYhmhl",
    "outputId": "86d23b0a-6d77-4454-b84a-538a90758826"
   },
   "outputs": [],
   "source": [
    "# Get the percentage of negative reviews\n",
    "n_rev = df_sentiment[df_sentiment['analysis_snd'] == 'negative']\n",
    "n_rev = n_rev['last_review']\n",
    "round((n_rev.shape[0] / df_sentiment.shape[0])*100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZRkImVYj5RW"
   },
   "source": [
    "Same thing in negative feedback but not so significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-PK_fxdkVVW"
   },
   "source": [
    "Let's see into the distribution of negative and positive feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "XIArFCzhkbeV",
    "outputId": "5fa95651-6728-46b0-a342-94b237233aef"
   },
   "outputs": [],
   "source": [
    "# plot and visualize\n",
    "\n",
    "plt.title('Sentiment Analysis 0f first comments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "df_sentiment['analysis_fst'].value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# show the value counts\n",
    "\n",
    "df_sentiment['analysis_fst'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "lWAOWUN8kmeG",
    "outputId": "12843478-ee0c-4e60-adc7-1d69e60bfa6f"
   },
   "outputs": [],
   "source": [
    "# plot and visualize\n",
    "\n",
    "plt.title('Sentiment Analysis 0f lastt comments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "df_sentiment['analysis_snd'].value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# show the value counts\n",
    "\n",
    "df_sentiment['analysis_snd'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLQL5JDKlHes"
   },
   "source": [
    "As we may see, more or less it is the same. We also note that we can't to refer to neutral comments because we replaced the missing values with 'No comments' and it gives us the neutral sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmVMEfckcoRx"
   },
   "source": [
    "### 2.9 url_ta column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JubEhjgWcoU5"
   },
   "source": [
    "We're not going to analyse this column. Just drop it in feture engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74_LsLsSgPgR"
   },
   "source": [
    "### 2.9 id_ta column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ue9P1OTZgPgR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform to numeric\n",
    "df['id_ta'] = df['id_ta'].apply(lambda x: int(x[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the counts of id\n",
    "df['id_ta'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFArP7F3gPgR"
   },
   "source": [
    "Well, we have some duplicates here. As per the dataset description, this is a univocal identifier for each restaurant. Drop duplicates in the feature engineering section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FkdOR_ggPgR"
   },
   "source": [
    "## 3. Feature Engineering and tidy dataset up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_PDaQ5qgPgS"
   },
   "source": [
    "### 3.1 Restaurant_Id column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ISlVL0DgPgS"
   },
   "source": [
    "With a reference to EDA provided in Section 2, we may add one additional column which depicts, whether the restaurant belongs to the chain or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NPFWo_BgPgS",
    "outputId": "5cc16e05-c726-4954-c311-c17a41ecdf84"
   },
   "outputs": [],
   "source": [
    "# Create a list with restaurants which might be in chain\n",
    "\n",
    "chained_rest_list = list(df['restaurant_id'].value_counts()[\n",
    "    df['restaurant_id'].value_counts() > 1].index)\n",
    "\n",
    "# If it is in chain, we add in a new column the identificator '1', otherwise '0'\n",
    "df['chained_rest'] = df[df['restaurant_id'].isin(\n",
    "    chained_rest_list)].restaurant_id.apply(lambda x: 1)\n",
    "df['chained_rest'] = df['chained_rest'].fillna(0)\n",
    "\n",
    "# Check\n",
    "df['chained_rest'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQNb0Pq9gPgS"
   },
   "source": [
    "### 3.2 City column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VxDhDj4gPgS"
   },
   "outputs": [],
   "source": [
    "# Fix Oporto\n",
    "df['city'] = df['city'].replace(['Oporto'], 'Porto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities = df['city'].value_counts().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63vopdH-gPgT"
   },
   "source": [
    "Let's add a column with information about whether the Restaurant is in capital or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4K8w5A-gPgT"
   },
   "outputs": [],
   "source": [
    "# Cos we don't have too many cities, let's create a dict where mention whether the city is a capital\n",
    "capital = [True, True, True, False, True, False, True,\n",
    "           True, True, True, True, True, False, False,\n",
    "           False, True, True, True, True, True, True,\n",
    "           True, False, False, False, False, True,\n",
    "           True, True, True, True]\n",
    "\n",
    "capital_dict = dict(zip(list(all_cities), capital))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ6MZHOXgPgT"
   },
   "outputs": [],
   "source": [
    "df['capital'] = df['city'].map(capital_dict)\n",
    "\n",
    "# show data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W17OlbymgPgU"
   },
   "source": [
    "Add the population and add information to what country the city belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-w2e9W2qgPgU"
   },
   "outputs": [],
   "source": [
    "city_population = {\n",
    "    'London': 8787892,\n",
    "    'Paris': 2187526,\n",
    "    'Madrid': 3300000,\n",
    "    'Barcelona': 1593075,\n",
    "    'Berlin': 3726902,\n",
    "    'Milan': 1331586,\n",
    "    'Rome': 2860000,\n",
    "    'Prague': 1300000,\n",
    "    'Lisbon': 505526,\n",
    "    'Vienna': 1900000,\n",
    "    'Amsterdam': 872080,\n",
    "    'Brussels': 144784,\n",
    "    'Hamburg': 1840000,\n",
    "    'Munich': 1558395,\n",
    "    'Lyon': 506615,\n",
    "    'Stockholm': 975904,\n",
    "    'Budapest': 1752286,\n",
    "    'Warsaw': 1720398,\n",
    "    'Dublin': 1793579,\n",
    "    'Copenhagen': 1330993,\n",
    "    'Athens': 3090508,\n",
    "    'Edinburgh': 476100,\n",
    "    'Zurich': 402275,\n",
    "    'Porto': 237559,\n",
    "    'Geneva': 196150,\n",
    "    'Krakow': 779115,\n",
    "    'Oslo': 697549,\n",
    "    'Helsinki':  656229,\n",
    "    'Bratislava': 563682,\n",
    "    'Luxembourg': 626108,\n",
    "    'Ljubljana': 295504\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9quWleQIgPgU"
   },
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "259v0E7FgPgU"
   },
   "outputs": [],
   "source": [
    "city_country = {\n",
    "    'London': 'United Kingdom',\n",
    "    'Paris': 'France',\n",
    "    'Madrid': 'Spain',\n",
    "    'Barcelona': 'Spain',\n",
    "    'Berlin': 'Germany',\n",
    "    'Milan': 'Italy',\n",
    "    'Rome': 'Italy',\n",
    "    'Prague': 'Czech',\n",
    "    'Lisbon': 'Portugal',\n",
    "    'Vienna': 'Austria',\n",
    "    'Amsterdam': 'Netherlands',\n",
    "    'Brussels': 'Belgium',\n",
    "    'Hamburg': 'Germany',\n",
    "    'Munich': 'Germany',\n",
    "    'Lyon': 'France',\n",
    "    'Stockholm': 'Sweden',\n",
    "    'Budapest': 'Hungary',\n",
    "    'Warsaw': 'Poland',\n",
    "    'Dublin': 'Ireland',\n",
    "    'Copenhagen': 'Denmark',\n",
    "    'Athens': 'Greece',\n",
    "    'Edinburgh': 'Schotland',\n",
    "    'Zurich': 'Switzerland',\n",
    "    'Porto': 'Portugal',\n",
    "    'Geneva': 'Switzerland',\n",
    "    'Krakow': 'Poland',\n",
    "    'Oslo': 'Norway',\n",
    "    'Helsinki': 'Finland',\n",
    "    'Bratislava': 'Slovakia',\n",
    "    'Luxembourg': 'Luxembourg',\n",
    "    'Ljubljana': 'Slovenija'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBXQRNBQgPgU"
   },
   "outputs": [],
   "source": [
    "# add columns with the city population\n",
    "df['city_population'] = df['city'].map(city_population)\n",
    "\n",
    "# add column with countries\n",
    "df['country'] = df['city'].map(city_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of not populasr cities\n",
    "df['new_city'] = df['city']\n",
    "# Create a top Cites list (more than 70% in Dataset)\n",
    "top_cities_list = df['new_city'].value_counts()[\n",
    "    df['new_city'].value_counts() > np.percentile((df['new_city'].value_counts().values), 70)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_to_drop = list(set(all_cities)-set(top_cities_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['new_city'].isin(cities_to_drop), 'new_city'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5), dpi=100)\n",
    "sns.countplot(df['new_city'], order=df['new_city'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Cities Distribution\\n', fontsize=15)\n",
    "plt.xlabel('City Name')\n",
    "plt.ylabel('Quantity (frequency)')\n",
    "\n",
    "print(f'Total Number of Cities in DataSet: {df.city.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the city column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NI-ngsfGgPgV"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_city = pd.DataFrame(OH_encoder.fit_transform(df[['new_city']]))\n",
    "\n",
    "# Adding column names to the encoded data set.\n",
    "OH_city.columns = OH_encoder.get_feature_names(['new_city'])\n",
    "\n",
    "# Show data\n",
    "OH_city.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder() # create an object\n",
    "# le.fit(df['city'])\n",
    "# df['city_CODE'] = le.transform(df['city'])\n",
    "\n",
    "# #show data\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the Country column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OH_country = pd.DataFrame(OH_encoder.fit_transform(df[['country']]))\n",
    "\n",
    "# # Adding column names to the encoded data set.\n",
    "# OH_country.columns = OH_encoder.get_feature_names(['country'])\n",
    "\n",
    "# # Show data\n",
    "# OH_country.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()  # create an object\n",
    "le.fit(df['country'])\n",
    "df['country_CODE'] = le.transform(df['country'])\n",
    "\n",
    "# show data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.concat([OH_city, OH_country], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_test.corr()\n",
    "\n",
    "# print(f'Rank of Matrix: {np.linalg.matrix_rank(X)}')\n",
    "# print(f'Determinat of matrix :{np.round(np.linalg.det(X),3)}')\n",
    "# print(f'Shape of matrix :{np.shape(X)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiHF2l6DgPgV"
   },
   "source": [
    "### 3.3 Cuisine_style column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhTS-5SBgPgV"
   },
   "source": [
    "Let's add a new feature - the quantity of cuisine in a restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzAkHI74gPgV"
   },
   "outputs": [],
   "source": [
    "df['cuisine_count'] = df['cuisine_style'].apply(lambda x: len(x))\n",
    "\n",
    "# show data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dUz7EWjgPgW"
   },
   "source": [
    "Add one more feature which tells that restaurant has in its set a rare cuisine.\n",
    "\n",
    "Assume rare value if it is met in dataset less than 50 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuLPSSzFgPgW"
   },
   "outputs": [],
   "source": [
    "cuisine_rare_lst = df.explode('cuisine_style')['cuisine_style'].value_counts()[\n",
    "    df.explode('cuisine_style')['cuisine_style'].value_counts() < 50].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONrzuHUWgPgW"
   },
   "outputs": [],
   "source": [
    "def get_cuisine_rare(row):\n",
    "    '''Function called for creating a number of\n",
    "    rare cuisins\n",
    "    INPUT: A cell from dataset\n",
    "    OUTPUT: Number of rare cuisins'''\n",
    "\n",
    "    number = 0\n",
    "    for i in cuisine_rare_lst:\n",
    "        if i in row:\n",
    "            number += 1  # count qty of rare cuisines\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tKNHkUEgPgW"
   },
   "outputs": [],
   "source": [
    "# create a column with rare cuisine and call func\n",
    "df['rare_cuisine'] = df['cuisine_style'].apply(get_cuisine_rare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvW9ny4BgPgW"
   },
   "source": [
    "Is it important to know (perhaps), whether the cuisine belongs to the region where it is coming from?\n",
    "\n",
    "Let's add this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJNKB6degPgX"
   },
   "outputs": [],
   "source": [
    "# Create a global variable (dict) with cuisines and related region of it\n",
    "# I don't know how to use NLP for this case, so this work need to be done by hands :(\n",
    "\n",
    "cuisine_region = {\n",
    "    'France': ['French', 'Central European'],\n",
    "    'Sweden': ['Swedish', 'Scandinavian'],\n",
    "    'United Kingdom': ['British'],\n",
    "    'Germany': ['German', 'Central European'],\n",
    "    'Italy': ['Pizza', 'Italian'],\n",
    "    'Slovakia': ['Eastern European'],\n",
    "    'Austria': ['Austrian'],\n",
    "    'Spain': ['Spanish'],\n",
    "    'Ireland': ['Irish'],\n",
    "    'Belgium': ['Belgian'],\n",
    "    'Switzerland': ['Swiss'],\n",
    "    'Poland': ['Polish', 'Ukrainian'],\n",
    "    'Hungary': ['Hungarian'],\n",
    "    'Denmark': ['Scandinavian'],\n",
    "    'Netherlands': ['Dutch'],\n",
    "    'Portugal': ['Portuguese'],\n",
    "    'Czech': ['Czech'],\n",
    "    'Norway': ['Norwegian', 'Scandinavian'],\n",
    "    'Finland': ['Central European'],\n",
    "    'Schotland': ['Scottish'],\n",
    "    'Slovenija': ['Slovenian'],\n",
    "    'Greece': ['Greek'],\n",
    "    'Luxembourg': ['Central European']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shVV_CS0gPgX"
   },
   "outputs": [],
   "source": [
    "# Create a function for identification of local cuisine\n",
    "\n",
    "def get_local_cuisine(row):\n",
    "    '''Function called for identifying\n",
    "    whether restaurant includes local\n",
    "    cuisine or not\n",
    "    INPUT: A cell from dataset\n",
    "    OUTPUT: 1 - if includes\n",
    "            0 - if does not include'''\n",
    "\n",
    "    local_cuis = cuisine_region[row['country']]\n",
    "    for i in local_cuis:\n",
    "        if i in row['cuisine_style'] and i != '':\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHl2u7wcgPgX"
   },
   "outputs": [],
   "source": [
    "# create a column with identificator, whether cuisine is local\n",
    "df['local_cuisine'] = df.apply(get_local_cuisine, axis=1)\n",
    "\n",
    "# count them\n",
    "df['local_cuisine'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_xXgOc9gPgY",
    "outputId": "5b0c75df-8195-4c84-94a8-217e45e9cd48"
   },
   "source": [
    "Our dataset has 13455 cuisines that belong to the country of origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gjxo5KPgPgY"
   },
   "source": [
    "With a reference to our EDA, we noticed that the Vegan and Gluten-Free Options are very likely to be reviewed by the customers. Let's add the feature, whether a restaurant includes vegan food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p19iJnYcgPgY"
   },
   "outputs": [],
   "source": [
    "# create a func to identify, whether restaurant includes vegan food\n",
    "\n",
    "def get_vegan(row):\n",
    "    vegan_cuis = ['Vegetarian Friendly', 'Vegan Options',  # All vegan food in my oppinion\n",
    "                  'Gluten Free Options', 'Healthy', ]\n",
    "    for i in vegan_cuis:\n",
    "        if i in row['cuisine_style'] and i != '':\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLbn4UaWgPgY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a new column with identification, whether restaurant includes a vegan food\n",
    "df['vegan_include'] = df.apply(get_vegan, axis=1)\n",
    "\n",
    "# Show Data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode a cuisine column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cuisine_encode = df['cuisine_style'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use a standard pandas method 'get dummies'\n",
    "# df_cuisine_encod = pd.get_dummies(df_cuisine_encode, dummy_na=True)\n",
    "# # show data\n",
    "# df_cuisine_encode.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OH_cuisine = pd.DataFrame(OH_encoder.fit_transform(df[['cuisine_style']]))\n",
    "\n",
    "# # Adding column names to the encoded data set.\n",
    "# OH_cuisine.columns = OH_encoder.get_feature_names(['cuisine_style'])\n",
    "\n",
    "# # Show data\n",
    "# OH_cuisine.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocvIrVuPgPgZ"
   },
   "source": [
    "### 3.4 Ranking column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G2akcF5gPgZ"
   },
   "source": [
    "With a reference to EDA section 2.5 let's create a column with equivalent ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDgTDT2kgPgZ"
   },
   "source": [
    "Step 1: Create a total number of a restaurants in a single city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3uOm9KKgPgZ"
   },
   "outputs": [],
   "source": [
    "city_restaurant = dict(df['city'].value_counts())\n",
    "df['restaurant_qty'] = df['city'].map(city_restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M65rRvCVgPga"
   },
   "source": [
    "Step 2: Create an equivalent ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LjxcbxfgPga"
   },
   "outputs": [],
   "source": [
    "# devide ranking in dataset by quantity of restaurants in a city\n",
    "df['equiv_ranking'] = df['ranking']/df['restaurant_qty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qBCwRdOgPga"
   },
   "source": [
    "Step 3. Check distribution of a normalized ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "KlpnyPATgPga",
    "outputId": "dfc748aa-1a34-4e35-e8b8-85655e6446ec"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for city in (df['city'].value_counts())[0:10].index:\n",
    "    sns.distplot(df['equiv_ranking'][df['city'] == city],\n",
    "                 kde=False, label=city)\n",
    "\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.title('Equivalent ranking Distribution among cities\\n', fontsize=15)\n",
    "plt.xlabel('Equivalent ranking')\n",
    "plt.ylabel('Quantity (frequency)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETIy5X4wgPga"
   },
   "source": [
    "Well, now it looks better than in section 2.5. Distribution is normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWN3omfWgPgb"
   },
   "source": [
    "Create a column with mean value of people to a single restaurant in a city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbTvhJwjgPgb"
   },
   "outputs": [],
   "source": [
    "df['people_per_restaur'] = df['city_population']/df['restaurant_qty']\n",
    "# Show Data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column with with equivalent to reviews number ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['reviews_in_city'] = df['city'].apply(lambda x: df.groupby(\n",
    "    ['city'])['reviews_number'].sum().sort_values(ascending=False)[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['equivalent_rank_reviews'] = df['ranking'] / df['reviews_in_city']\n",
    "\n",
    "# Show Data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9Nz_PIogPgb"
   },
   "source": [
    "### 3.5 Price range column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_range'] = df.price_range.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CNTwjH8gEX5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()  # create an object\n",
    "le.fit(df['price_range'])\n",
    "df['price_range'] = le.transform(df['price_range'])\n",
    "\n",
    "# show data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Reviews number column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['reviews_number'] = df['reviews_number'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the sort of smart filling of missing values. As we know from EDA section, there is a column 'Last review' with some comments, while the Reviews number is empty. So we might assume that it is a kind of mistake.\n",
    "\n",
    "Let's fill the NaN in this manner:\n",
    "\n",
    "If there is 1 comment in a ’Last Review‘ or 'First review', we put '1' into a Review Numbers column.\n",
    "\n",
    "In case of nor the first comment neither the second filled, put 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes long for computing\n",
    "# You may comment it and just run next one\n",
    "\n",
    "df['reviews_number'] = df.apply(\n",
    "    lambda row: 1 if np.isnan(row['reviews_number']) and (row['last_review_miss'] == 0 or row['first_review_miss'] == 0) else row['reviews_number'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(df['reviews_number']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. we filled some missed reviews number. Rest of them fill with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_number'] = df['reviews_number'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Diff_rev column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply replace the NaN values by zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill and check the Nan values\n",
    "df['diff_rev'] = df['diff_rev'].fillna(0)\n",
    "df['days_from_last_rev'] = df['days_from_last_rev'].fillna(0)\n",
    "\n",
    "display(df['diff_rev'].isna().sum())\n",
    "df['days_from_last_rev'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 MAP the Data frame to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['restaurant_id', 'city', 'new_city', 'cuisine_style',\n",
    "                'url_ta', 'reviews', 'first_review',\n",
    "                'last_review', 'first_date', 'last_date', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_model = df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code several times and it was determined, that following columns has negative effect on the final MAE. Drop them out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column with subjectivity in a sentiment analys data frame has negative effect on to MAE. Do not include it in final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dataframes\n",
    "\n",
    "df_to_model = pd.concat(\n",
    "    [df_to_model, df_sentiment[['polarity_fst', 'polarity_snd']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_to_model = pd.concat([df_to_model, OH_city], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop2 = ['new_city_Barcelona', 'cuisine_style_empty', 'new_city_Paris',\n",
    "                 'last_review_miss', 'new_city_London', 'price_range',\n",
    "                 'new_city_Lisbon', 'chained_rest', 'new_city_Berlin', 'rare_cuisine',\n",
    "                 'first_review_miss', 'capital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_model = df_to_model.drop(cols_to_drop2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Resulting dataframe verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot missing values\n",
    "cols = df_to_model.columns\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.heatmap(df_to_model[cols].isnull(), cmap=sns.color_palette(colors))\n",
    "\n",
    "#Show in percents\n",
    "\n",
    "for col in df_to_model.columns:\n",
    "    pct_missing = np.mean(df_to_model[col].isnull())\n",
    "    print(f'{col} - {round(pct_missing*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_model['id_ta'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Col 'id_ta' has duplicates. However the final result will be worst in case we remove them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_to_model.corr()\n",
    "# fig, ax = plt.subplots(figsize=(50, 50))\n",
    "# sns.heatmap(X, vmax=.7, square=True, annot=True)\n",
    "print(f'Rank of Matrix: {np.linalg.matrix_rank(X)}')\n",
    "print(f'Shape of matrix :{np.shape(X)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final matrix of data has a full rank. Shall not be a problem to feed this data in a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Split data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Х - данные с информацией о ресторанах, у - целевая переменная (рейтинги ресторанов)\n",
    "X = df_to_model.drop(['rating'], axis=1)\n",
    "y = df_to_model['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем специальный инструмент для разбивки:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n",
    "# Для тестирования мы будем использовать 25% от исходного датасета.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "# инструмент для создания и обучения модели\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics  # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "regr = RandomForestRegressor(\n",
    "    n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be observed that the difference in that real ratings are always multiples of 0.5\n",
    "# Write a function to round the predicted ratings accordingly\n",
    "def round_rating_pred(rating_pred):\n",
    "    if rating_pred <= 0.5:\n",
    "        return 0.0\n",
    "    if rating_pred <= 1.5:\n",
    "        return 1.0\n",
    "    if rating_pred <= 1.75:\n",
    "        return 1.5\n",
    "    if rating_pred <= 2.25:\n",
    "        return 2.0\n",
    "    if rating_pred <= 2.75:\n",
    "        return 2.5\n",
    "    if rating_pred <= 3.25:\n",
    "        return 3.0\n",
    "    if rating_pred <= 3.75:\n",
    "        return 3.5\n",
    "    if rating_pred <= 4.25:\n",
    "        return 4.0\n",
    "    if rating_pred <= 4.75:\n",
    "        return 4.5\n",
    "    return 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round it\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = round_rating_pred(y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Trip_advisor_Who_likes_to_eat.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
